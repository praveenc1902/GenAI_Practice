{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f1e7bcb-7b07-47e1-a10b-d7b9b8c8bb98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-openai in /opt/anaconda3/lib/python3.11/site-packages (0.1.1)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-openai) (0.1.33)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-openai) (1.14.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-openai) (0.6.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (6.0.1)\n",
      "Requirement already satisfied: anyio<5,>=3 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (4.2.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (0.1.31)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (23.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (1.10.12)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from langchain-core<0.2.0,>=0.1.33->langchain-openai) (8.2.2)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /opt/anaconda3/lib/python3.11/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (4.9.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/anaconda3/lib/python3.11/site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.10.3)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/anaconda3/lib/python3.11/site-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain-openai) (3.4)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/anaconda3/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.2.0,>=0.1.33->langchain-openai) (3.9.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.33->langchain-openai) (2.0.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76b6d8c4-61cb-45f1-a677-597653cfd031",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3811a2a3-3b6e-425c-9f8b-3ee8c19f193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "996b58c0-7246-4a6e-8cd7-2ee884f1f047",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(openai_api_key = OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "956f41a3-6561-4936-81f8-dc8f9aaa7ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage,SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74e6b559-b695-4793-a930-74fd708dff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"you are a powerful assistant\"),\n",
    "    HumanMessage(content=\"What is the purpose of Model Regularization\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "477c6a9a-f6da-4c14-b89c-b3b740a4ed45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Model regularization is a technique used in machine learning to prevent overfitting, which occurs when a model learns to perform well on the training data but fails to generalize to new, unseen data. Regularization helps to reduce the complexity of a model by adding a penalty term to the model's loss function, encouraging the model to prioritize simpler solutions that are less likely to overfit.\\n\\nThere are various types of regularization techniques, such as L1 regularization (Lasso), L2 regularization (Ridge), and elastic net regularization, each of which applies a different type of penalty to the model's parameters. Regularization helps to improve the model's performance on unseen data and makes it more robust and reliable in real-world applications.\", response_metadata={'token_usage': {'completion_tokens': 143, 'prompt_tokens': 24, 'total_tokens': 167}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c92aa73-90af-4785-9a96-3ab187104903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Model regularization is a technique used in machine learning to prevent overfitting and improve the generalization of a model. Overfitting occurs when a model learns the training data too well, capturing noise and random fluctuations that are specific to the training data but do not generalize to new, unseen data. Regularization helps to control the complexity of a model by adding a penalty term to the loss function, discouraging the model from fitting the training data too closely.\\n\\nThere are different types of regularization techniques, such as L1 regularization (Lasso), L2 regularization (Ridge), and elastic net regularization, which can help to reduce overfitting and improve the performance of a model on unseen data. Regularization is an essential tool in machine learning to balance model complexity and model performance, making the model more robust and reliable for real-world applications.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model.invoke(messages)\n",
    "output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5118f6e-f41b-4b44-b635-1525f3d520e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content=\"Model regularization is a technique used in machine learning to prevent overfitting and improve the generalization of a model. Overfitting occurs when a model learns the training data too well, including noise or random fluctuations, which can negatively impact its performance on unseen data. Regularization helps to address this issue by adding a penalty term to the model's loss function, which discourages the model from becoming too complex or fitting the training data too closely.\\n\\nThere are different types of regularization techniques, such as L1 regularization (Lasso), L2 regularization (Ridge), and Elastic Net regularization, which all aim to control the complexity of the model and prevent overfitting. By incorporating regularization into the training process, the model can learn more robust patterns from the data and make better predictions on new, unseen data.\", response_metadata={'token_usage': {'completion_tokens': 162, 'prompt_tokens': 24, 'total_tokens': 186}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None})]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.batch([messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6b931be-5c05-4222-9815-12ee0be530c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content = \"you are helpful assistant who converts the english text to telugu and vice versa\"),\n",
    "    HumanMessage(content = \"I love you my dear Wife\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a00e143c-8866-44ed-9844-5c367d7ca109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='నేను నా ప్రియమైన భార్యను ప్రేమిస్తున్నాను', response_metadata={'token_usage': {'completion_tokens': 74, 'prompt_tokens': 32, 'total_tokens': 106}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4e1958c-288b-4dbe-8c97-899ba3a17c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'నేను నా ప్రియ భార్యను ప్రేమిస్తున్నాను'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(messages).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f3f4518-2f1a-4a6b-974a-7c6776691edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_messages = [\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant that translates English to Telugu.\"\n",
    "        ),\n",
    "        HumanMessage(content=\"I love programming.\"),\n",
    "    ],\n",
    "    [\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant that translates English to Hindi.\"\n",
    "        ),\n",
    "        HumanMessage(content=\"I love artificial intelligence.\"),\n",
    "    ],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "10c65c62-aeda-4600-a2b9-bf509cd8612c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[AIMessage(content='నాకు ప్రోగ్రమింగ్ ఇష్టం.', response_metadata={'token_usage': {'completion_tokens': 43, 'prompt_tokens': 27, 'total_tokens': 70}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None}),\n",
       " AIMessage(content='मुझे कृत्रिम बुद्धिमत्ता पसंद है।', response_metadata={'token_usage': {'completion_tokens': 35, 'prompt_tokens': 27, 'total_tokens': 62}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3bc1b5746c', 'finish_reason': 'stop', 'logprobs': None})]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# result = \n",
    "model.batch(batch_messages)\n",
    "# result.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
