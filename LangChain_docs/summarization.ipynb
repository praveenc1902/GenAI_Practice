{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0050ab3e-cd50-487c-a417-29da96d3b63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_openai import ChatOpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2a75f6f-e32b-4ed9-87ee-59189d8ac11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "docs = loader.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91863145-044a-468c-a961-4460b83e7c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65a1da52-e2fc-4609-93ba-34408e66b0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e274cffa-7706-4fb4-a46e-a2b49c00b059",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = load_summarize_chain(llm,chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4fe3988-fad8-440f-80a7-951824c390c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The article discusses the concept of building autonomous agents powered by Large Language Models (LLMs). It explores the components of such agents, including planning, memory, and tool use, with examples such as scientific discovery agents and generative agents simulation. Challenges such as finite context length, reliability of natural language interface, and long-term planning are highlighted. The article also references various studies and projects in this domain.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09cf2640-2ea6-4acc-98bd-8628acf45c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents.stuff import StuffDocumentsChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ccf0d01b-5f5e-42e7-850b-bc8bc6c26603",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "Write a concise summary of the following:\n",
    "\"{text}\"\n",
    "CONCISE SUMMARY:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ce7de3dd-eba8-44eb-8d4d-f577a9a6a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d861c0a5-d179-4177-9166-3cd6340eeb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=llm,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "72105b70-99be-413a-b894-bc05a73ac8e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The article discusses the concept of building autonomous agents powered by large language models (LLMs), focusing on planning, memory, and tool use components. It includes examples like AutoGPT, GPT-Engineer, and generative agents simulation. Challenges include finite context length, reliability of natural language interface, and long-term planning difficulties. The article provides a detailed overview of the key components and case studies, highlighting the potential of LLMs in creating powerful problem-solving agents.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stuff_chain  = StuffDocumentsChain(llm_chain=llm_chain,document_variable_name='text')\n",
    "stuff_chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56b0c2c0-93b1-4442-969e-1dd91f930e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_reduce approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40885606-7502-451f-aa4e-6adab669970e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['docs'], template='The following is a set of documents\\n{docs}\\nBased on this list of docs, please identify the main themes \\nHelpful Answer:')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import MapReduceDocumentsChain, ReduceDocumentsChain\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# Map\n",
    "map_template = \"\"\"The following is a set of documents\n",
    "{docs}\n",
    "Based on this list of docs, please identify the main themes \n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(map_template)\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f65c821d-16fa-4096-9794-baea3999bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_chain = LLMChain(llm=llm,prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0b550a8-ebd0-4b24-a6f2-6ba8e7eed615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchainhub\n",
      "  Using cached langchainhub-0.1.15-py3-none-any.whl.metadata (621 bytes)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from langchainhub) (2.31.0)\n",
      "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
      "  Downloading types_requests-2.31.0.20240406-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchainhub) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchainhub) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchainhub) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.11/site-packages (from requests<3,>=2->langchainhub) (2024.2.2)\n",
      "Using cached langchainhub-0.1.15-py3-none-any.whl (4.6 kB)\n",
      "Downloading types_requests-2.31.0.20240406-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: types-requests, langchainhub\n",
      "Successfully installed langchainhub-0.1.15 types-requests-2.31.0.20240406\n"
     ]
    }
   ],
   "source": [
    "!pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "252f8f8a-91a0-49fe-93f4-8da71c07b2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "\n",
    "map_prompt = hub.pull(\"rlm/map-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b24c2ee2-c8f0-43ed-afc2-7456597d4687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['docs'], metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'map-prompt', 'lc_hub_commit_hash': 'de4fba345f211a462584fc25b7077e69c1ba6cdcf4e21b7ec9abe457ddb16c87'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['docs'], template='The following is a set of documents:\\n{docs}\\nBased on this list of docs, please identify the main themes \\nHelpful Answer:'))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02e16d66-f661-44fb-8c22-80321004f9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce\n",
    "reduce_template = \"\"\"The following is set of summaries:\n",
    "{docs}\n",
    "Take these and distill it into a final, consolidated summary of the main themes. \n",
    "Helpful Answer:\"\"\"\n",
    "reduce_prompt = PromptTemplate.from_template(reduce_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e4f7862a-1560-4570-a0ce-7643d915762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_chain = LLMChain(llm=llm,prompt=reduce_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "acf08b1e-70dc-474a-a20f-425de0775f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_documents_chain = StuffDocumentsChain(\n",
    "    llm_chain=reduce_chain, document_variable_name=\"docs\"\n",
    ")\n",
    "\n",
    "# Combines and iteratively reduces the mapped documents\n",
    "reduce_documents_chain = ReduceDocumentsChain(\n",
    "    # This is final chain that is called.\n",
    "    combine_documents_chain=combine_documents_chain,\n",
    "    # If documents exceed context for `StuffDocumentsChain`\n",
    "    collapse_documents_chain=combine_documents_chain,\n",
    "    # The maximum number of tokens to group documents into.\n",
    "    token_max=4000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "447b7cb5-e46f-40d1-a419-6dfeacde52d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_reduce_chain = MapReduceDocumentsChain(\n",
    "    llm_chain=map_chain,\n",
    "    reduce_documents_chain=reduce_documents_chain,\n",
    "    document_variable_name=\"docs\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "766369d5-8634-4562-97eb-3371aeb4fe40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 1003, which is longer than the specified 1000\n"
     ]
    }
   ],
   "source": [
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=1000, chunk_overlap=0\n",
    ")\n",
    "split_docs = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6fcab3e-d5eb-4a79-82a9-8bb4ef90d794",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The main themes identified across the provided documents include building autonomous agents powered by large language models (LLMs), components of LLM-powered agents such as planning, memory, and tool use, task decomposition, self-reflection, and memory types in agent systems, case studies and proof-of-concept examples of LLM-powered agents, challenges in building and utilizing LLM-powered agents, memory optimization techniques like MIPS and LSH, algorithms for nearest neighbor search, neuro-symbolic architecture for agents, fine-tuning language models with external tools, task planning and model selection using language models, and challenges and limitations in the development and application of LLM-powered agents. These themes collectively highlight the advancements, applications, and challenges in leveraging LLMs for building intelligent autonomous systems.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_reduce_chain.run(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "234ed9f3-921e-4d7d-8b04-6013536be98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#refine method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ccdd46a1-f409-4f61-a345-3ec3d917494d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Write a concise summary of the following:\n",
    "{text}\n",
    "CONCISE SUMMARY:\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9619098e-ff28-4e06-b004-33066dd3fbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_template = (\n",
    "    \"Your job is to produce a final summary\\n\"\n",
    "    \"We have provided an existing summary up to a certain point: {existing_answer}\\n\"\n",
    "    \"We have the opportunity to refine the existing summary\"\n",
    "    \"(only if needed) with some more context below.\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"{text}\\n\"\n",
    "    \"------------\\n\"\n",
    "    \"Given the new context, refine the original summary in Italian\"\n",
    "    \"If the context isn't useful, return the original summary.\"\n",
    ")\n",
    "refine_prompt = PromptTemplate.from_template(refine_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "159ffad1-ff60-46f5-85c9-f1e526ecfe9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type=\"refine\",\n",
    "    question_prompt=prompt,\n",
    "    refine_prompt=refine_prompt,\n",
    "    return_intermediate_steps=True,\n",
    "    input_key=\"input_documents\",\n",
    "    output_key=\"output_text\",\n",
    ")\n",
    "result = chain({\"input_documents\": split_docs}, return_only_outputs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4615dfe3-9566-4a63-b885-e4fee1c7cd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intermediate_steps': ['The article discusses the concept of building autonomous agents powered by LLM (large language models) and highlights key components such as planning, memory, and tool use. It explores proof-of-concept examples like AutoGPT and GPT-Engineer, demonstrating the potential of LLM beyond generating text and programs. The agent system leverages LLM for problem-solving and task decomposition, self-reflection, and external tool use, making it a powerful general problem solver.',\n",
       "  \"L'articolo discute il concetto di costruire agenti autonomi alimentati da grandi modelli linguistici (LLM) e mette in evidenza componenti chiave come la pianificazione, la memoria e l'uso degli strumenti. Esplora esempi di prova concettuali come AutoGPT e GPT-Engineer, dimostrando il potenziale degli LLM oltre alla generazione di testi e programmi. Il sistema di agenti sfrutta gli LLM per la risoluzione di problemi e la decomposizione delle attività, l'auto-riflessione e l'uso di strumenti esterni, rendendolo un potente risolutore generale di problemi. Inoltre, vengono presentati approcci come la decomposizione delle attività, l'auto-riflessione e l'uso di piani esterni per la pianificazione a lungo termine.\",\n",
       "  \"L'articolo discute il concetto di costruire agenti autonomi alimentati da grandi modelli linguistici (LLM) e mette in evidenza componenti chiave come la pianificazione, la memoria e l'uso degli strumenti. Esplora esempi di prova concettuali come AutoGPT e GPT-Engineer, dimostrando il potenziale degli LLM oltre alla generazione di testi e programmi. Il sistema di agenti sfrutta gli LLM per la risoluzione di problemi e la decomposizione delle attività, l'auto-riflessione e l'uso di strumenti esterni, rendendolo un potente risolutore generale di problemi. Vengono presentati approcci come la decomposizione delle attività, l'auto-riflessione e l'uso di piani esterni per la pianificazione a lungo termine. L'articolo introduce anche due nuovi approcci: Chain of Hindsight (CoH) che migliora gli output dei modelli attraverso feedback sequenziali e Algorithm Distillation (AD) che applica lo stesso concetto alle traiettorie di apprendimento per il reinforcement learning, dimostrando una maggiore efficienza nell'apprendimento rispetto ai baselines.\",\n",
       "  \"L'articolo discute il concetto di costruire agenti autonomi alimentati da grandi modelli linguistici (LLM) e mette in evidenza componenti chiave come la pianificazione, la memoria e l'uso degli strumenti. Esplora esempi di prova concettuali come AutoGPT e GPT-Engineer, dimostrando il potenziale degli LLM oltre alla generazione di testi e programmi. Il sistema di agenti sfrutta gli LLM per la risoluzione di problemi e la decomposizione delle attività, l'auto-riflessione e l'uso di strumenti esterni, rendendolo un potente risolutore generale di problemi. Vengono presentati approcci come la decomposizione delle attività, l'auto-riflessione e l'uso di piani esterni per la pianificazione a lungo termine. L'articolo introduce anche due nuovi approcci: Chain of Hindsight (CoH) che migliora gli output dei modelli attraverso feedback sequenziali e Algorithm Distillation (AD) che applica lo stesso concetto alle traiettorie di apprendimento per il reinforcement learning, dimostrando una maggiore efficienza nell'apprendimento rispetto ai baselines. Inoltre, vengono esplorati i diversi tipi di memoria umana, come la memoria sensoriale, la memoria a breve termine e la memoria a lungo termine, per comprendere meglio come le informazioni vengono acquisite, conservate e recuperate.\",\n",
       "  \"L'articolo discute il concetto di costruire agenti autonomi alimentati da grandi modelli linguistici (LLM) e mette in evidenza componenti chiave come la pianificazione, la memoria e l'uso degli strumenti. Esplora esempi di prova concettuali come AutoGPT e GPT-Engineer, dimostrando il potenziale degli LLM oltre alla generazione di testi e programmi. Il sistema di agenti sfrutta gli LLM per la risoluzione di problemi e la decomposizione delle attività, l'auto-riflessione e l'uso di strumenti esterni, rendendolo un potente risolutore generale di problemi. Vengono presentati approcci come la decomposizione delle attività, l'auto-riflessione e l'uso di piani esterni per la pianificazione a lungo termine. L'articolo introduce anche due nuovi approcci: Chain of Hindsight (CoH) che migliora gli output dei modelli attraverso feedback sequenziali e Algorithm Distillation (AD) che applica lo stesso concetto alle traiettorie di apprendimento per il reinforcement learning, dimostrando una maggiore efficienza nell'apprendimento rispetto ai baselines. Inoltre, vengono esplorati i diversi tipi di memoria umana, come la memoria sensoriale, la memoria a breve termine e la memoria a lungo termine, per comprendere meglio come le informazioni vengono acquisite, conservate e recuperate. L'uso degli strumenti esterni è una caratteristica distintiva degli esseri umani e dotare gli LLM di strumenti esterni può estendere significativamente le capacità del modello.\",\n",
       "  \"L'articolo discute il concetto di costruire agenti autonomi alimentati da grandi modelli linguistici (LLM) e mette in evidenza componenti chiave come la pianificazione, la memoria e l'uso degli strumenti. Esplora esempi di prova concettuali come AutoGPT e GPT-Engineer, dimostrando il potenziale degli LLM oltre alla generazione di testi e programmi. Il sistema di agenti sfrutta gli LLM per la risoluzione di problemi e la decomposizione delle attività, l'auto-riflessione e l'uso di strumenti esterni, rendendolo un potente risolutore generale di problemi. Vengono presentati approcci come la decomposizione delle attività, l'auto-riflessione e l'uso di piani esterni per la pianificazione a lungo termine. L'articolo introduce anche due nuovi approcci: Chain of Hindsight (CoH) che migliora gli output dei modelli attraverso feedback sequenziali e Algorithm Distillation (AD) che applica lo stesso concetto alle traiettorie di apprendimento per il reinforcement learning, dimostrando una maggiore efficienza nell'apprendimento rispetto ai baselines. Inoltre, vengono esplorati i diversi tipi di memoria umana, come la memoria sensoriale, la memoria a breve termine e la memoria a lungo termine, per comprendere meglio come le informazioni vengono acquisite, conservate e recuperate. L'uso degli strumenti esterni è una caratteristica distintiva degli esseri umani e dotare gli LLM di strumenti esterni può estendere significativamente le capacità del modello. Inoltre, vengono presentati approcci come MRKL, TALM, e Toolformer che consentono agli LLM di apprendere l'uso di strumenti esterni, come API di calcolatori, dimostrando la necessità di saper utilizzare tali strumenti in modo efficace per migliorare le prestazioni complessive del modello.\",\n",
       "  \"L'articolo discute il concetto di costruire agenti autonomi alimentati da grandi modelli linguistici (LLM) e mette in evidenza componenti chiave come la pianificazione, la memoria e l'uso degli strumenti. Esplora esempi di prova concettuali come AutoGPT e GPT-Engineer, dimostrando il potenziale degli LLM oltre alla generazione di testi e programmi. Il sistema di agenti sfrutta gli LLM per la risoluzione di problemi e la decomposizione delle attività, l'auto-riflessione e l'uso di strumenti esterni, rendendolo un potente risolutore generale di problemi. Vengono presentati approcci come la decomposizione delle attività, l'auto-riflessione e l'uso di piani esterni per la pianificazione a lungo termine. L'articolo introduce anche due nuovi approcci: Chain of Hindsight (CoH) che migliora gli output dei modelli attraverso feedback sequenziali e Algorithm Distillation (AD) che applica lo stesso concetto alle traiettorie di apprendimento per il reinforcement learning, dimostrando una maggiore efficienza nell'apprendimento rispetto ai baselines. Inoltre, vengono esplorati i diversi tipi di memoria umana, come la memoria sensoriale, la memoria a breve termine e la memoria a lungo termine, per comprendere meglio come le informazioni vengono acquisite, conservate e recuperate. L'uso degli strumenti esterni è una caratteristica distintiva degli esseri umani e dotare gli LLM di strumenti esterni può estendere significativamente le capacità del modello. Inoltre, vengono presentati approcci come MRKL, TALM, e Toolformer che consentono agli LLM di apprendere l'uso di strumenti esterni, come API di calcolatori, dimostrando la necessità di saper utilizzare tali strumenti in modo efficace per migliorare le prestazioni complessive del modello. Inoltre, viene presentato il benchmark API-Bank per valutare le prestazioni degli LLM con strumenti esterni, insieme a casi di studio come ChemCrow e agenti per la scoperta scientifica, evidenziando le sfide e le potenzialità nell'utilizzo degli LLM in contesti reali.\",\n",
       "  \"L'articolo discute il concetto di costruire agenti autonomi alimentati da grandi modelli linguistici (LLM) e mette in evidenza componenti chiave come la pianificazione, la memoria e l'uso degli strumenti. Esplora esempi di prova concettuali come AutoGPT e GPT-Engineer, dimostrando il potenziale degli LLM oltre alla generazione di testi e programmi. Il sistema di agenti sfrutta gli LLM per la risoluzione di problemi e la decomposizione delle attività, l'auto-riflessione e l'uso di strumenti esterni, rendendolo un potente risolutore generale di problemi. Vengono presentati approcci come la decomposizione delle attività, l'auto-riflessione e l'uso di piani esterni per la pianificazione a lungo termine. L'articolo introduce anche due nuovi approcci: Chain of Hindsight (CoH) che migliora gli output dei modelli attraverso feedback sequenziali e Algorithm Distillation (AD) che applica lo stesso concetto alle traiettorie di apprendimento per il reinforcement learning, dimostrando una maggiore efficienza nell'apprendimento rispetto ai baselines. Inoltre, vengono esplorati i diversi tipi di memoria umana, come la memoria sensoriale, la memoria a breve termine e la memoria a lungo termine, per comprendere meglio come le informazioni vengono acquisite, conservate e recuperate. L'uso degli strumenti esterni è una caratteristica distintiva degli esseri umani e dotare gli LLM di strumenti esterni può estendere significativamente le capacità del modello. Vengono presentati approcci come MRKL, TALM, e Toolformer che consentono agli LLM di apprendere l'uso di strumenti esterni, come API di calcolatori, dimostrando la necessità di saper utilizzare tali strumenti in modo efficace per migliorare le prestazioni complessive del modello. Inoltre, viene presentato il benchmark API-Bank per valutare le prestazioni degli LLM con strumenti esterni, insieme a casi di studio come ChemCrow e agenti per la scoperta scientifica, evidenziando le sfide e le potenzialità nell'utilizzo degli LLM in contesti reali. Infine, il testo introduce l'esperimento Generative Agents, in cui agenti alimentati da LLM interagiscono in un ambiente sandbox, dimostrando la capacità di creare simulacri di comportamenti umani per applicazioni interattive.\",\n",
       "  \"L'articolo discute il concetto di costruire agenti autonomi alimentati da grandi modelli linguistici (LLM) e mette in evidenza componenti chiave come la pianificazione, la memoria, l'uso degli strumenti e la valutazione delle prestazioni. Esplora esempi di prova concettuali come AutoGPT e GPT-Engineer, dimostrando il potenziale degli LLM oltre alla generazione di testi e programmi. Il sistema di agenti sfrutta gli LLM per la risoluzione di problemi e la decomposizione delle attività, l'auto-riflessione e l'uso di strumenti esterni, rendendolo un potente risolutore generale di problemi. Vengono presentati approcci come la decomposizione delle attività, l'auto-riflessione e l'uso di piani esterni per la pianificazione a lungo termine. L'articolo introduce anche due nuovi approcci: Chain of Hindsight (CoH) che migliora gli output dei modelli attraverso feedback sequenziali e Algorithm Distillation (AD) che applica lo stesso concetto alle traiettorie di apprendimento per il reinforcement learning, dimostrando una maggiore efficienza nell'apprendimento rispetto ai baselines. Inoltre, vengono esplorati i diversi tipi di memoria umana, come la memoria sensoriale, la memoria a breve termine e la memoria a lungo termine, per comprendere meglio come le informazioni vengono acquisite, conservate e recuperate. L'uso degli strumenti esterni è una caratteristica distintiva degli esseri umani e dotare gli LLM di strumenti esterni può estendere significativamente le capacità del modello. Vengono presentati approcci come MRKL, TALM, e Toolformer che consentono agli LLM di apprendere l'uso di strumenti esterni, come API di calcolatori, dimostrando la necessità di saper utilizzare tali strumenti in modo efficace per migliorare le prestazioni complessive del modello. Inoltre, viene presentato il benchmark API-Bank per valutare le prestazioni degli LLM con strumenti esterni, insieme a casi di studio come ChemCrow e agenti per la scoperta scientifica, evidenziando le sfide e le potenzialità nell'utilizzo degli LLM in contesti reali. Infine, il testo introduce l'esperimento Generative Agents, in cui agenti alimentati da LLM interagiscono in un ambiente sandbox, dimostrando la capacità di creare simulacri di comportamenti umani per applicazioni interattive.\",\n",
       "  '{\\n    \"thoughts\": {\\n        \"text\": \"The additional context provided about GPT-Engineer and the sample conversation for task clarification is interesting and relevant for understanding how the system works.\",\\n        \"reasoning\": \"It adds a layer of depth to the discussion around building autonomous agents powered by large language models like GPT-Engineer.\",\\n        \"plan\": \"- Incorporate the details about GPT-Engineer and the task clarification conversation into the summary to provide a more comprehensive overview.\",\\n        \"criticism\": \"No specific criticism to address.\",\\n        \"speak\": \"I will enhance the original summary with the new context about GPT-Engineer and the task clarification process.\"\\n    },\\n    \"command\": {\\n        \"name\": \"update_summary\",\\n        \"args\": {\\n            \"original_summary\": \"L\\'articolo discute il concetto di costruire agenti autonomi alimentati da grandi modelli linguistici (LLM) e mette in evidenza componenti chiave come la pianificazione, la memoria, l\\'uso degli strumenti e la valutazione delle prestazioni...\",\\n            \"additional_context\": \"GPT-Engineer is another project to create a whole repository of code given a task specified in natural language. The GPT-Engineer is instructed to think over a list of smaller components to build and ask for user input to clarify questions as needed...\"\\n        }\\n    }\\n}',\n",
       "  \"L'articolo discute il concetto di costruire agenti autonomi alimentati da grandi modelli linguistici (LLM) e mette in evidenza componenti chiave come la pianificazione, la memoria, l'uso degli strumenti e la valutazione delle prestazioni. Inoltre, viene introdotto il progetto GPT-Engineer che mira a creare un intero repository di codice data una specifica attività espressa in linguaggio naturale. GPT-Engineer è istruito a pensare a una lista di componenti più piccoli da costruire e a chiedere il contributo dell'utente per chiarire eventuali domande. Questo aggiornamento fornisce una visione più dettagliata del funzionamento del sistema e del processo di chiarimento delle attività.\",\n",
       "  \"L'articolo discute il concetto di costruire agenti autonomi alimentati da grandi modelli linguistici (LLM) e mette in evidenza componenti chiave come la pianificazione, la memoria, l'uso degli strumenti e la valutazione delle prestazioni. Viene introdotto il progetto GPT-Engineer che mira a creare un intero repository di codice data una specifica attività espressa in linguaggio naturale. GPT-Engineer è istruito a pensare a una lista di componenti più piccoli da costruire e a chiedere il contributo dell'utente per chiarire eventuali domande. Questo aggiornamento fornisce una visione più dettagliata del funzionamento del sistema e del processo di chiarimento delle attività. Inoltre, vengono fornite istruzioni dettagliate su come scrivere codice seguendo passo dopo passo le decisioni prese e garantendo che ogni dettaglio dell'architettura sia implementato correttamente.\",\n",
       "  \"L'articolo discute il concetto di costruire agenti autonomi alimentati da grandi modelli linguistici (LLM) e mette in evidenza componenti chiave come la pianificazione, la memoria, l'uso degli strumenti e la valutazione delle prestazioni. Viene introdotto il progetto GPT-Engineer che mira a creare un intero repository di codice data una specifica attività espressa in linguaggio naturale. GPT-Engineer è istruito a pensare a una lista di componenti più piccoli da costruire e a chiedere il contributo dell'utente per chiarire eventuali domande. Questo aggiornamento fornisce una visione più dettagliata del funzionamento del sistema e del processo di chiarimento delle attività, con particolare attenzione alle sfide nel piano a lungo termine e nella decomposizione dei compiti, nonché alla affidabilità dell'interfaccia in linguaggio naturale. Inoltre, vengono fornite istruzioni dettagliate su come scrivere codice seguendo passo dopo passo le decisioni prese e garantendo che ogni dettaglio dell'architettura sia implementato correttamente.\",\n",
       "  \"Il presente articolo discute il concetto di costruire agenti autonomi alimentati da grandi modelli linguistici (LLM) e mette in evidenza componenti chiave come la pianificazione, la memoria, l'uso degli strumenti e la valutazione delle prestazioni. Viene introdotto il progetto GPT-Engineer che mira a creare un intero repository di codice data una specifica attività espressa in linguaggio naturale. GPT-Engineer è istruito a pensare a una lista di componenti più piccoli da costruire e a chiedere il contributo dell'utente per chiarire eventuali domande. Questo aggiornamento fornisce una visione più dettagliata del funzionamento del sistema e del processo di chiarimento delle attività, con particolare attenzione alle sfide nel piano a lungo termine e nella decomposizione dei compiti, nonché alla affidabilità dell'interfaccia in linguaggio naturale. Inoltre, vengono fornite istruzioni dettagliate su come scrivere codice seguendo passo dopo passo le decisioni prese e garantendo che ogni dettaglio dell'architettura sia implementato correttamente. Il lavoro si basa su ricerche recenti nel campo delle tecnologie linguistiche, come il prompting elicits reasoning in large language models, l'empowerment dei large language models con optimal planning proficiency e la sinergia tra reasoning e acting in language models.\"],\n",
       " 'output_text': \"Il presente articolo discute il concetto di costruire agenti autonomi alimentati da grandi modelli linguistici (LLM) e mette in evidenza componenti chiave come la pianificazione, la memoria, l'uso degli strumenti e la valutazione delle prestazioni. Viene introdotto il progetto GPT-Engineer che mira a creare un intero repository di codice data una specifica attività espressa in linguaggio naturale. GPT-Engineer è istruito a pensare a una lista di componenti più piccoli da costruire e a chiedere il contributo dell'utente per chiarire eventuali domande. Questo aggiornamento fornisce una visione più dettagliata del funzionamento del sistema e del processo di chiarimento delle attività, con particolare attenzione alle sfide nel piano a lungo termine e nella decomposizione dei compiti, nonché alla affidabilità dell'interfaccia in linguaggio naturale. Inoltre, vengono fornite istruzioni dettagliate su come scrivere codice seguendo passo dopo passo le decisioni prese e garantendo che ogni dettaglio dell'architettura sia implementato correttamente. Il lavoro si basa su ricerche recenti nel campo delle tecnologie linguistiche, come il prompting elicits reasoning in large language models, l'empowerment dei large language models con optimal planning proficiency e la sinergia tra reasoning e acting in language models.\"}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6421d41b-6e0e-46d5-b655-b9fe485d03b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
