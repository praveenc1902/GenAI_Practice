{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9150d56e-8ff9-4ebc-bff4-8a9d2c560d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from typing import Literal, Optional, Tuple\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class SubQuery(BaseModel):\n",
    "    \"\"\"Search over a database of tutorial videos about a software library.\"\"\"\n",
    "    sub_query:str = Field(...,\n",
    "        description = \"A very specific query against the database.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdba32f1-757e-4d28-bc0d-eba45d5f415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY =\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3e47e9e-b5ea-4bc4-ad7a-bc0661c238b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticToolsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "system = \"\"\"You are an expert at converting user questions into database queries. \\\n",
    "You have access to a database of tutorial videos about a software library for building LLM-powered applications. \\\n",
    "\n",
    "Perform query decomposition. Given a user question, break it down into distinct sub questions that \\\n",
    "you need to answer in order to answer the original question.\n",
    "\n",
    "If there are acronyms or words you are not familiar with, do not try to rephrase them.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",system),\n",
    "        (\"human\",\"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY)\n",
    "llm_with_tools = llm.bind_tools([SubQuery])\n",
    "parser = PydanticToolsParser(tools=[SubQuery])\n",
    "\n",
    "query_analyser = prompt | llm | parser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dd4dc36-a212-47c2-ac94-eba84e89509e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyser.invoke({\"question\":\"how to use multi-modal models in a chain and turn chain into a rest api\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9c3e1624-ea16-4baa-a3d2-575c5fd76a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyser.invoke({\"question\":\"what is RAG\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94f11ce7-e9e6-4963-b3bd-0db9b51ad427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "class ParaphrasedQuery(BaseModel):\n",
    "    \"\"\"You have performed query expansion to generate a paraphrasing of a question.\"\"\"\n",
    "\n",
    "    paraphrased_query: str = Field(\n",
    "        ...,\n",
    "        description=\"A unique paraphrasing of the original question.\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2173d587-b09c-405b-9b64-32a0543adb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import PydanticToolsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "system = \"\"\"You are an expert at converting user questions into database queries. \\\n",
    "You have access to a database of tutorial videos about a software library for building LLM-powered applications. \\\n",
    "\n",
    "Perform query expansion. If there are multiple common ways of phrasing a user question \\\n",
    "or common synonyms for key words in the question, make sure to return multiple versions \\\n",
    "of the query with the different phrasings.\n",
    "\n",
    "If there are acronyms or words you are not familiar with, do not try to rephrase them.\n",
    "\n",
    "Return at least 3 versions of the question.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "llm_with_tools = llm.bind_tools([ParaphrasedQuery])\n",
    "query_analyzer = prompt | llm_with_tools | PydanticToolsParser(tools=[ParaphrasedQuery])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20535c1a-c068-4366-873a-d9f97719a996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ParaphrasedQuery(paraphrased_query='How to utilize multi-modal models in a sequence and convert the sequence into a REST API'),\n",
       " ParaphrasedQuery(paraphrased_query='Using multi-modal models sequentially and transforming the sequence into a RESTful API'),\n",
       " ParaphrasedQuery(paraphrased_query='Guide on employing multi-modal models in a chain and converting the chain into a REST API')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_analyzer.invoke(\n",
    "    {\n",
    "        \"question\": \"how to use multi-modal models in a chain and turn chain into a rest api\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e9ea1c-8f47-40ea-ab2d-d3119bae088e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
